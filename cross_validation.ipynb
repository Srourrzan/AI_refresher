{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9fde00-379d-4586-8720-57ae8760a768",
   "metadata": {},
   "source": [
    "#### The following examples are taken from the official scikit learn website documentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43758bc-9f20-4286-83df-7b3459a03c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn import datasets;\n",
    "from sklearn import svm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b04cb42-5b37-4dea-bc1e-eb10980c69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (150, 4), y.shape = (150,)\n"
     ]
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True);\n",
    "print(f\"X.shape = {X.shape}, y.shape = {y.shape}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a081bc5b-50e0-47f2-9ffc-79b141719f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (90, 4), y_train.shape = (90,)\n",
      "X_test.shape = (60, 4), y_test.shape = (60,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0);\n",
    "print(f\"X_train.shape = {X_train.shape}, y_train.shape = {y_train.shape}\");\n",
    "print(f\"X_test.shape = {X_test.shape}, y_test.shape = {y_test.shape}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc32e66a-7fcb-433b-8f6d-c50df811a061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train);\n",
    "print(f\"score = {clf.score(X_test, y_test)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceee0da-0b50-40a6-a853-d9e37497583a",
   "metadata": {},
   "source": [
    "In the k-fold CV, the training set is split into k smaller sets. The following procedure is followed for each of the k \"folds\":\n",
    "\n",
    "* A model is trained using `k - 1` of the folds as training data;\n",
    "* The resulting model is validated on the remaining part of the data, it's used as a test set to compute a performance measure such as accuracy.\n",
    "\n",
    "The performance measure resported by k-fold cross-validation is then the average of the values computed in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86f7f4a-8911-4fd8-9602-e0daa6ef67d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.9800000000000001 accuracy with a standard deviation of 0.016329931618554516\n"
     ]
    }
   ],
   "source": [
    "# use cross_val_score\n",
    "from sklearn.model_selection import cross_val_score;\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42);\n",
    "scores = cross_val_score(clf, X, y, cv=5);\n",
    "print(f\"scores: {scores}\");\n",
    "print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ce867a-f25c-4cfc-8d32-93bb269b7167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.96658312 1.         0.96658312 0.96658312 1.        ]\n",
      "0.9799498746867169 accuracy with a standard deviation of 0.016370858765468226\n"
     ]
    }
   ],
   "source": [
    "# The score computed at each CV iteration is the score method of the estimator.\n",
    "# It is possible to change this by using the scoring parameter:\n",
    "from sklearn import metrics\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro');\n",
    "print(f\"scores: {scores}\");\n",
    "print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7295d3f8-90b4-43d8-a7d5-d4ec97a948ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.97777778 0.97777778 1.         0.95555556 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# to use other cross validation strategies, pass a cross validation iterator\n",
    "from sklearn.model_selection import ShuffleSplit;\n",
    "#n_samples = X.shape[0];\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0);\n",
    "print(f\"score: {cross_val_score(clf, X, y, cv=cv)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b25c37-de70-46c0-a576-0c0a54ce9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [1.         0.97333333]\n"
     ]
    }
   ],
   "source": [
    "# another option is to use an iterable yielding (train, test)\n",
    "def custom_cv_2folds(X: np.ndarray):\n",
    "    n = X.shape[0];\n",
    "    i = 1;\n",
    "    while i <= 2:\n",
    "        idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int);\n",
    "        yield idx, idx;\n",
    "        i += 1;\n",
    "\n",
    "custom_cv = custom_cv_2folds(X);\n",
    "print(f\"scores: {cross_val_score(clf, X, y, cv=custom_cv)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe897d1-bdb1-42fd-81aa-828d290b9f9c",
   "metadata": {},
   "source": [
    "The `cross_validate` function differes from `cross_val_score` in two ways:\n",
    "\n",
    "* It allows specifying mulitple metrics for evaluation.\n",
    "* It returns a dict containing fit-times, score-times (optional: training scores, fitted estimators, train-test split) also the test score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4493f689-40be-436b-84b9-0549c9d1aa2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated scores: ['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n"
     ]
    }
   ],
   "source": [
    "# multiple metrics\n",
    "from sklearn.model_selection import cross_validate;\n",
    "from sklearn.metrics import recall_score;\n",
    "scoring = ['precision_macro', 'recall_macro'];\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0);\n",
    "scores = cross_validate(clf, X, y, scoring=scoring);\n",
    "sort = sorted(scores.keys());\n",
    "print(f\"calculated scores: {sort}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e846db4e-d43e-4b5b-922c-000ef6292517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: [0.0025897  0.00168729 0.00174332 0.0015254  0.00142384]\n",
      "score_time: [0.00719547 0.00505853 0.00430751 0.00493288 0.00613737]\n",
      "test_precision_macro: [0.96969697 1.         0.96969697 0.96969697 1.        ]\n",
      "test_recall_macro: [0.96666667 1.         0.96666667 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "for key in scores.keys():\n",
    "    print(f\"{key}: {scores[key]}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c833b05-fc11-4ee0-a8a9-c65b20eb6071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: [0.00212765 0.001472   0.00154805 0.00139213 0.00135851]\n",
      "score_time: [0.00445461 0.0047586  0.00423384 0.00459552 0.00437593]\n",
      "indices: {'train': (array([ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,\n",
      "        23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
      "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
      "        49,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "        72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "        98,  99, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  20,  21,  22,\n",
      "        23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
      "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
      "        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  70,  71,\n",
      "        72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  30,  31,  32,  33,  34,  35,\n",
      "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
      "        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
      "        62,  63,  64,  65,  66,  67,  68,  69,  80,  81,  82,  83,  84,\n",
      "        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "       111, 112, 113, 114, 115, 116, 117, 118, 119, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
      "        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
      "        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "        75,  76,  77,  78,  79,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "       111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "       124, 125, 126, 127, 128, 129, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
      "        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "        88,  89, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "       111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "       124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "       137, 138, 139])), 'test': (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  50,  51,  52,\n",
      "        53,  54,  55,  56,  57,  58,  59, 100, 101, 102, 103, 104, 105,\n",
      "       106, 107, 108, 109]), array([ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  60,  61,  62,\n",
      "        63,  64,  65,  66,  67,  68,  69, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119]), array([ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  70,  71,  72,\n",
      "        73,  74,  75,  76,  77,  78,  79, 120, 121, 122, 123, 124, 125,\n",
      "       126, 127, 128, 129]), array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  80,  81,  82,\n",
      "        83,  84,  85,  86,  87,  88,  89, 130, 131, 132, 133, 134, 135,\n",
      "       136, 137, 138, 139]), array([ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  90,  91,  92,\n",
      "        93,  94,  95,  96,  97,  98,  99, 140, 141, 142, 143, 144, 145,\n",
      "       146, 147, 148, 149]))}\n",
      "test_prec_macro: [0.96969697 1.         0.96969697 0.96969697 1.        ]\n",
      "train_prec_macro: [0.97674419 0.97674419 0.99186992 0.98412698 0.98333333]\n",
      "test_rec_macro: [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "train_rec_macro: [0.975      0.975      0.99166667 0.98333333 0.98333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer;\n",
    "scoring = {'prec_macro': 'precision_macro',\n",
    "           'rec_macro': make_scorer(recall_score, average='macro')};\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5, return_train_score=True, return_indices=True);\n",
    "for key in scores.keys():\n",
    "    print(f\"{key}: {scores[key]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880a3c3-cc4b-49a2-9fda-495f16532606",
   "metadata": {},
   "source": [
    "**Obtaining perdictions by cross-validation**\n",
    "\n",
    "The function `cross_val_predict` has a similar interface to `cross_val_score`, but returns, for each element in the input, the prediction that was obtained for that element when it was in the test set. Only cross-validation strategies that assign all elements to a test set exactly one can be used.\n",
    "\n",
    "`cross_val_predict` is not an appropriate measure of generalization error. But it's appropriate for:\n",
    "\n",
    "* Visualization of predictions obtained from different models.\n",
    "* Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd2b900-555b-42f1-8f33-43c62489b07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n",
      "X_train: \n",
      "[[0 0]\n",
      " [1 1]]\n",
      "X_test: \n",
      "[[-1 -1]\n",
      " [ 2  2]]\n"
     ]
    }
   ],
   "source": [
    "# KFold\n",
    "# Example of 2-fold cross-validation on a dataset with 4 samples\n",
    "from sklearn.model_selection import KFold;\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"];\n",
    "kf = KFold(n_splits=2);\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test));\n",
    "\n",
    "# Each fold is constituted by two arrays: the first one is related to the training set,\n",
    "# and the second one to the test set. Thus, one can create the training/test set using numpy indexing:\n",
    "X = np.array([[0, 0], [1, 1], [-1, -1], [2, 2]]);\n",
    "y = np.array([0, 1, 0, 1]);\n",
    "X_train, X_test, y_train, t_test = X[train], X[test], y[train], y[test];\n",
    "print(f\"X_train: \\n{X_train}\");\n",
    "print(f\"X_test: \\n{X_test}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac37604-4014-4cc4-91c0-607ecd4ea703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [2 3]\n",
      "[2 3] [0 1]\n",
      "[1 3] [0 2]\n",
      "[0 2] [1 3]\n"
     ]
    }
   ],
   "source": [
    "# Repeated K-Fold\n",
    "# It repeats KFold n times, producing different splits in each repetition\n",
    "from sklearn.model_selection import RepeatedKFold;\n",
    "\n",
    "X = np.array([[1, 2], [3, 2], [1, 2], [3, 4]]);\n",
    "random_state = 1288;\n",
    "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state);\n",
    "for train, test in rkf.split(X):\n",
    "    print(\"%s %s\" % (train, test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "799b331e-a229-441a-ad3f-269800dd766f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n"
     ]
    }
   ],
   "source": [
    "# Leave One Out (LOO)\n",
    "# is a simple cross-validation. Each learning set is created by taking all the samples except one, \n",
    "# the test set being the sample left out. Thus, for n samples, we have n different training sets\n",
    "# and n different test sets. This cross-validation procedure does not waste much data as only one\n",
    "# sample is removed from the training set:\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut;\n",
    "\n",
    "X = [1, 2, 3, 4];\n",
    "loo = LeaveOneOut();\n",
    "for train, test in loo.split(X):\n",
    "    print(\"%s %s\" % (train, test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d259a05f-1992-49b0-bb5d-84cd9380f036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[1 3] [0 2]\n",
      "[1 2] [0 3]\n",
      "[0 3] [1 2]\n",
      "[0 2] [1 3]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "# Leave P Out (LPO)\n",
    "# It created all the possible training/test sets by removing `p` samples from the complete set.\n",
    "# For `n` samples, this produced (n p) train-test pairs. Unlike LeaveOneOut and KFold, the test\n",
    "# sets will overlap for p > 1.\n",
    "from sklearn.model_selection import LeavePOut;\n",
    "\n",
    "X = np.ones(4);\n",
    "lpo = LeavePOut(p=2);\n",
    "for train, test in lpo.split(X):\n",
    "    print(\"%s %s\" % (train, test));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b7eec-92e5-460d-9913-d5db8795323d",
   "metadata": {},
   "source": [
    "**Stratification**\n",
    "\n",
    "In case of rare classes, cross-validation splitting can generate train or validation folds without any occurance of a particular class. This typically leads to undefined classification metrics (e.g. `ROC AUC`), exceptions raised when attempting to call `fit` or missing columns in the output of the `predict_proba` or `decision_function` methods of multiclass classifiers trained on different folds.\n",
    "\n",
    "To mitigate such problems, splitters such as `StratidiedKFold` and `StratifiedShuffleSplit` implement stratidied sampling to ensure that relative class frequencies are approximately preserved in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63524431-9662-4701-b4d7-bff26af968c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold\n",
      "train - [30  3] | test - [15  2]\n",
      "train - [30  3] | test - [15  2]\n",
      "train - [30  4] | test - [15  1]\n",
      "\n",
      "KFold\n",
      "train - [28  5] | test - [17]\n",
      "train - [28  5] | test - [17]\n",
      "train - [34] | test - [11  5]\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold is a variation of K-fold which returns stratified folds:\n",
    "# each set contains approximately the same percentage of samples of each terget class\n",
    "# as the complete set.\n",
    "from sklearn.model_selection import StratifiedKFold;\n",
    "\n",
    "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5));\n",
    "skf = StratifiedKFold(n_splits=3);\n",
    "print(\"StratifiedKFold\");\n",
    "for train, test in skf.split(X, y):\n",
    "    print('train - {} | test - {}'.format(np.bincount(y[train]), np.bincount(y[test])));\n",
    "\n",
    "print(\"\\nKFold\");\n",
    "kf = KFold(n_splits=3);\n",
    "for train, test in kf.split(X, y):\n",
    "    print('train - {} | test - {}'.format(np.bincount(y[train]), np.bincount(y[test])));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd5e77-ce12-43b8-8d36-2ba31faae7b4",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74856122-98b7-47c4-9b1f-52e186056e8d",
   "metadata": {},
   "source": [
    "#### Tuning the hyper-parameters of an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e9738-cafa-45f5-a9f0-64e9344ac126",
   "metadata": {},
   "source": [
    "Two generic approaches to parameter search are provided in scikit-learn: for given values, `GridSearchCV` exhaustively considers all parameters combinations, while `RandomizedSearchCV` can sample a given number of candidates from a parameter space with a specified distribution. Both these tools have successive halving conterparts `HalvingGridSearchCV` and `HalvingRandomSearchCV`, which can be much faster at finding a good parameter combination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c0ac9a-1ef0-4970-bdb8-dfd2fdbd27f0",
   "metadata": {},
   "source": [
    "**Exhaustive Grid Search**\n",
    "It exhaustively generates candidates from a grid of parameter values specified with the \n",
    "`param_grid` paramter. \n",
    "\n",
    "```py\n",
    "para_grid = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "```\n",
    "\n",
    "The GridSearchCV instance implements the usual estimator API: when \"fitting\" it on a dataset\n",
    "all the possible combinations of parameter values are evaluated and the best combinationis retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1375cf6-ee57-4617-8467-87b5d9fbb8b3",
   "metadata": {},
   "source": [
    "**Randomized Parameter Optimization**\n",
    "It implements a randomized search over parameters, where each setting is sampled from a distribution\n",
    "over possible parameter values. This has two main benefits over an exhaustive search:\n",
    "* A budget can be chosen independent of the number of parameters and possible values.\n",
    "* Adding parameters that do not influence the performance does not decrease efficiency.\n",
    "Specifying how parameters should be samples is done using a dictionary, very similar to specifying parameters for `GridSearchCV`. Additionally, a computation budget, being the number of samples candidates or sampling iterations, specified using the `n_iter` parameter. For each parameter, either a distribution over possible values or alist of discrete choices (which will be sampled uniformaly) can be specified:\n",
    "\n",
    "```py\n",
    "{'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1),\n",
    "    'kernel': ['rbf'], 'class_weight': ['balanced', None]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59722750-b187-4cac-bf5e-f168dc4e9b7b",
   "metadata": {},
   "source": [
    "**Successive Halving (SH)**\n",
    "It's like a tournament among candidate parameter combinations. SH is an iterative selection process where all candidates (the parameter combinations) are evaluated with a small amount of resources at the first iteration. Only some of these candidates are selected for the next iteration, which will be allocated more resources. For parameter tuning, the resource is typically the number of training samples, but it can also be an arbitrary numeric parameter such as `n_estimators` in a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3bf24-b5c7-4083-831e-f4a7296a1660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
